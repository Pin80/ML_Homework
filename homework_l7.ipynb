{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание по теме «Функции потерь и оптимизация»\n",
    "Преподаватель: Алексей Кузьмин\n",
    "Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "\n",
    "Реализовать самостоятельно логистическую регрессию\n",
    "\n",
    "Обучить ее методом градиентного спуска\n",
    "Методом nesterov momentum\n",
    "Методом rmsprop\n",
    "В качестве dataset’а взять Iris, оставив 2 класса:\n",
    "\n",
    "Iris Versicolor\n",
    "Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( iris )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "target\n",
      "target_names\n",
      "DESCR\n",
      "feature_names\n",
      "filename\n"
     ]
    }
   ],
   "source": [
    "for key in iris.keys():\n",
    "    print( key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)\n",
    "print(type(iris.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sepal - чашелистик\n",
    "\n",
    "petal - лепесток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "145       2  \n",
      "146       2  \n",
      "147       2  \n",
      "148       2  \n",
      "149       2  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal length (cm)    150 non-null float64\n",
      "sepal width (cm)     150 non-null float64\n",
      "petal length (cm)    150 non-null float64\n",
      "petal width (cm)     150 non-null float64\n",
      "target               150 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 5.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['target'] = pd.Series(iris.target)\n",
    "print(data.head())\n",
    "print(data.tail())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "95                5.7               3.0                4.2               1.2   \n",
      "96                5.7               2.9                4.2               1.3   \n",
      "97                6.2               2.9                4.3               1.3   \n",
      "98                5.1               2.5                3.0               1.1   \n",
      "99                5.7               2.8                4.1               1.3   \n",
      "\n",
      "    target  \n",
      "95       1  \n",
      "96       1  \n",
      "97       1  \n",
      "98       1  \n",
      "99       1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      "sepal length (cm)    100 non-null float64\n",
      "sepal width (cm)     100 non-null float64\n",
      "petal length (cm)    100 non-null float64\n",
      "petal width (cm)     100 non-null float64\n",
      "target               100 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 4.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#drop samples with third class\n",
    "#data = data[((data['target'] == 0) or (data['target'] == 1))]\n",
    "label_a = data['target'] == 0\n",
    "label_b = data['target'] == 1\n",
    "data = data[label_a | label_b]\n",
    "print(data.head())\n",
    "print(data.tail())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "Y = data[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']] = \\\n",
    "    sc.fit_transform(X[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
    "print(Y.target.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-1.042111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-1.042111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.042111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.042111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-1.042111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0          -0.581066          0.841837          -1.012978         -1.042111\n",
       "1          -0.894309         -0.207835          -1.012978         -1.042111\n",
       "2          -1.207552          0.212034          -1.082312         -1.042111\n",
       "3          -1.364174          0.002099          -0.943643         -1.042111\n",
       "4          -0.737687          1.051772          -1.012978         -1.042111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/grad_descent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_log_loss(Y_label, Y_pred):\n",
    "    x_entropy_loss = 0\n",
    "    for yi, ypred in zip(Y_label, Y_pred):\n",
    "        if (ypred == 0):\n",
    "                print(\"error\")\n",
    "                return 1000\n",
    "        elif (ypred == 1):\n",
    "                print(\"error\")\n",
    "                return 1000\n",
    "        else:\n",
    "                x_entropy_loss += -yi * np.log(ypred) - (1. - yi) * np.log((1. - ypred))\n",
    "    return x_entropy_loss \n",
    "\n",
    "# Функция градиентного спуска. Моя переделка от стохастического градиента\n",
    "def get_grad_descent(X, Y_label):\n",
    "    my_sigmoid = lambda z: pd.DataFrame(1/(1 + np.exp(-z)))\n",
    "    h_theta = lambda X, Theta: my_sigmoid(X.dot( Theta))\n",
    "    X_curr = lambda X, l: X[X.columns[l]].transpose()\n",
    "    Xtheta0 = pd.DataFrame(np.ones(X.shape[0])) # For theta0 free member\n",
    "    X = X.join(Xtheta0)\n",
    "    L = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    l = 0\n",
    "    init_theta = 0.5\n",
    "    Theta = np.full(X.shape[1], init_theta)\n",
    "    Theta_old = np.full(X.shape[1], init_theta)\n",
    "    old_grad = 50;\n",
    "    eps = 0.000001 #\n",
    "    iteration_limit = 10000\n",
    "    iteration_current = 0\n",
    "    alpha = (1/N*L)*1  #learning rate\n",
    "    error = 1\n",
    "    error_hist = []\n",
    "    while (True):\n",
    "        # z = np.dot(X, Theta=) \n",
    "        # h = my_sigmoid(z)\n",
    "        grad_stohastic = []\n",
    "        grad_ = 0\n",
    "        for l in range(L):\n",
    "            ht = h_theta(X, Theta)\n",
    "            deltaY = ht[ht.columns[0]] - Y[Y.columns[0]]\n",
    "            tmpsum = X_curr(X, l).dot( deltaY )\n",
    "            grad_stohastic.append(tmpsum)\n",
    "            grad_ = sum(grad_stohastic)\n",
    "            Theta[l] = Theta[l] - alpha*grad_\n",
    "        #Theta_old = Theta\n",
    "        curr_grad = grad_\n",
    "        error = np.abs(curr_grad - old_grad)\n",
    "        old_grad = curr_grad;\n",
    "        iteration_current += 1\n",
    "        error_hist.append(error)\n",
    "        if ((error < eps) | (iteration_current > iteration_limit) | (error > 1000) ):\n",
    "            break\n",
    "    print(\"error:\", error)\n",
    "    print(\"old_grad\", old_grad)\n",
    "    print(\"error_hist[-1:-50:-1]\", error_hist[-1:-50:-1])\n",
    "    print(\"Theta\", Theta)\n",
    "    return Theta\n",
    "\n",
    "# Функция получения предсказаний\n",
    "def get_predictions(X, Y, Theta):\n",
    "    my_sigmoid = lambda z: 1/(1 + np.exp(-z))\n",
    "    h_theta = lambda z: my_sigmoid(z)\n",
    "    hyperplane_eq = lambda sample, Theta: sample.transpose().dot(Theta)\n",
    "    Xtheta0 = pd.DataFrame(np.ones(X.shape[0])) # For theta0 free member\n",
    "    X = X.join(Xtheta0)\n",
    "    L = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    Y_predictions = []\n",
    "    for i in range(N):\n",
    "        sample = X.iloc[i]\n",
    "        z = sample.transpose().dot( Theta)\n",
    "        probability_curr = h_theta(z)\n",
    "        Y_pred_curr = (probability_curr >= 0.5)\n",
    "        #print(i,\" \",Y_pred_curr, \" \",Y.iloc[i,0])\n",
    "        Y_predictions.append(Y_pred_curr)\n",
    "    Y_predictions = pd.DataFrame(Y_predictions)\n",
    "    return Y_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/nesterov.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оптимизации моментов Нестерова\n",
    "def get_grad_descent_nesterov(X, Y_label):\n",
    "    my_sigmoid = lambda z: pd.DataFrame(1/(1 + np.exp(-z)))\n",
    "    h_theta = lambda X, Theta: my_sigmoid(X.dot( Theta))\n",
    "    X_curr = lambda X, l: X[X.columns[l]].transpose()\n",
    "    Xtheta0 = pd.DataFrame(np.ones(X.shape[0])) # For theta0 free member\n",
    "    X = X.join(Xtheta0)\n",
    "    L = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    l = 0\n",
    "    init_theta = 0.5\n",
    "    Theta = np.full(X.shape[1], init_theta)\n",
    "    Theta_old = np.full(X.shape[1], init_theta)\n",
    "    Theta_sig = Theta\n",
    "    old_grad = 50;\n",
    "    eps = 0.000001 #\n",
    "    iteration_limit = 10000\n",
    "    iteration_current = 0\n",
    "    eta = (1/N*L)  #learning rate\n",
    "    mu = 0.8\n",
    "    new_m = 0\n",
    "    old_m = 0\n",
    "    error = 1\n",
    "    error_hist = []\n",
    "    while (True):\n",
    "        # z = np.dot(X, Theta=) \n",
    "        # h = my_sigmoid(z)\n",
    "        grad_stohastic = []\n",
    "        grad_ = 0\n",
    "        for l in range(L):\n",
    "            Theta_sig = Theta - eta*mu*old_m\n",
    "            ht = h_theta(X, Theta_sig)\n",
    "            deltaY = ht[ht.columns[0]] - Y[Y.columns[0]]\n",
    "            tmpsum = X_curr(X, l).dot( deltaY )\n",
    "            grad_stohastic.append(tmpsum)\n",
    "            grad_ = sum(grad_stohastic)\n",
    "            new_m = mu*old_m + grad_\n",
    "            Theta[l] = Theta[l] - eta*new_m\n",
    "        #Theta_old = Theta\n",
    "        old_m = new_m\n",
    "        curr_grad = grad_\n",
    "        error = np.abs(curr_grad - old_grad)\n",
    "        old_grad = curr_grad;\n",
    "        iteration_current += 1\n",
    "        error_hist.append(error)\n",
    "        if ((error < eps) | (iteration_current > iteration_limit) | (error > 1000) ):\n",
    "            break\n",
    "    print(\"error:\", error)\n",
    "    print(\"old_grad\", old_grad)\n",
    "    print(\"error_hist[-1:-50:-1]\", error_hist[-1:-50:-1])\n",
    "    print(\"Theta\", Theta)\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/rmsprop.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оптимизации rmsprop\n",
    "def get_rmsprop(X, Y_label):\n",
    "    my_sigmoid = lambda z: pd.DataFrame(1/(1 + np.exp(-z)))\n",
    "    h_theta = lambda X, Theta: my_sigmoid(X.dot( Theta))\n",
    "    X_curr = lambda X, l: X[X.columns[l]].transpose()\n",
    "    Xtheta0 = pd.DataFrame(np.ones(X.shape[0])) # For theta0 free member\n",
    "    X = X.join(Xtheta0)\n",
    "    L = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    l = 0\n",
    "    init_theta = 0.5\n",
    "    Theta = np.full(X.shape[1], init_theta)\n",
    "    Theta_old = np.full(X.shape[1], init_theta)\n",
    "    Theta_sig = Theta\n",
    "    old_grad = 50;\n",
    "    eps = 0.000001 #\n",
    "    iteration_limit = 10000\n",
    "    iteration_current = 0\n",
    "    eta = (1/N*L)  #learning rate\n",
    "    v = 0.8\n",
    "    eps_rms = 0.1 #\n",
    "    new_n = 0\n",
    "    old_n = 0\n",
    "    error = 1\n",
    "    error_hist = []\n",
    "    while (True):\n",
    "        # z = np.dot(X, Theta=) \n",
    "        # h = my_sigmoid(z)\n",
    "        grad_stohastic = []\n",
    "        grad_ = 0\n",
    "        for l in range(L):\n",
    "            Theta_sig = Theta\n",
    "            ht = h_theta(X, Theta_sig)\n",
    "            deltaY = ht[ht.columns[0]] - Y[Y.columns[0]]\n",
    "            tmpsum = X_curr(X, l).dot( deltaY )\n",
    "            grad_stohastic.append(tmpsum)\n",
    "            grad_ = sum(grad_stohastic)\n",
    "            new_n = v*old_n + (1-v)*np.square(grad_)\n",
    "            Theta[l] = Theta[l] - eta*grad_/(np.sqrt(new_n) + eps_rms)\n",
    "        #Theta_old = Theta\n",
    "        old_n = new_n\n",
    "        curr_grad = grad_\n",
    "        error = np.abs(curr_grad - old_grad)\n",
    "        old_grad = curr_grad;\n",
    "        iteration_current += 1\n",
    "        error_hist.append(error)\n",
    "        if ((error < eps) | (iteration_current > iteration_limit) | (error > 1000) ):\n",
    "            break\n",
    "    print(\"error:\", error)\n",
    "    print(\"old_grad\", old_grad)\n",
    "    print(\"error_hist[-1:-50:-1]\", error_hist[-1:-50:-1])\n",
    "    print(\"Theta\", Theta)\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 9.998704483130463e-07\n",
      "old_grad -0.002121674408647859\n",
      "error_hist[-1:-50:-1] [9.998704483130463e-07, 1.0008060907793284e-06, 1.0017430419305418e-06, 1.0026813032134457e-06, 1.0036208775683966e-06, 1.00456176583847e-06, 1.0055039685310727e-06, 1.0064474924298406e-06, 1.007392338050854e-06, 1.0083385093059144e-06, 1.0092860027698103e-06, 1.0102348305500441e-06, 1.0111849876332651e-06, 1.012136478814249e-06, 1.0130893089432824e-06, 1.0140434712384641e-06, 1.0149989828215147e-06, 1.015955834563452e-06, 1.0169140339235869e-06, 1.0178735804318093e-06, 1.0188344833446036e-06, 1.0197967384543982e-06, 1.0207603457620604e-06, 1.02172531833266e-06, 1.022691651975105e-06, 1.0236593494432691e-06, 1.0246284085453292e-06, 1.0255988434097404e-06, 1.0265706479380826e-06, 1.0275438310667837e-06, 1.0285183855611793e-06, 1.0294943216960367e-06, 1.03047164065357e-06, 1.0314503489147059e-06, 1.0324304374077081e-06, 1.0334119216791685e-06, 1.034394795317549e-06, 1.0353790653788372e-06, 1.0363647359587155e-06, 1.0373518053450118e-06, 1.0383402771927883e-06, 1.0393301583064979e-06, 1.0403214446841336e-06, 1.0413141466386264e-06, 1.042308256988221e-06, 1.043303786760555e-06, 1.0443007422700212e-06, 1.0452991094662273e-06, 1.0462989062281006e-06]\n",
      "Theta [ 3.53783199 -2.35810794  3.18411115  7.84660463  3.51996796]\n",
      "error: 9.998187677200815e-07\n",
      "old_grad -0.0011627935029621516\n",
      "error_hist[-1:-50:-1] [9.998187677200815e-07, 1.0015617569452545e-06, 1.0033093307132424e-06, 1.005061492399817e-06, 1.0068182721752889e-06, 1.0085796789162382e-06, 1.0103457321088138e-06, 1.0121164482224804e-06, 1.0138918354034993e-06, 1.0156719252012864e-06, 1.0174567185213673e-06, 1.0192462429406413e-06, 1.0210405153431718e-06, 1.0228395424562164e-06, 1.0246433488434598e-06, 1.0264519543345257e-06, 1.028265368335085e-06, 1.0300836097675015e-06, 1.0319067042709879e-06, 1.0337346565223587e-06, 1.0355674917323504e-06, 1.0374052248612181e-06, 1.0392478761219598e-06, 1.0410954541361511e-06, 1.0429479927187568e-06, 1.0448054916598754e-06, 1.0466679842887489e-06, 1.0485354778374395e-06, 1.0504079961358437e-06, 1.0522855518561164e-06, 1.0541681687327442e-06, 1.0560558618335353e-06, 1.0579486527818177e-06, 1.0598465515886807e-06, 1.061749587463398e-06, 1.0636577747035608e-06, 1.0655711271921608e-06, 1.067489669985544e-06, 1.0694134227450663e-06, 1.0713423974264419e-06, 1.0732766169609803e-06, 1.0752161009805472e-06, 1.0771608710147956e-06, 1.0791109389066827e-06, 1.0810663277505822e-06, 1.0830270642699091e-06, 1.0849931595391382e-06, 1.0869646256891907e-06, 1.088941504806193e-06]\n",
      "Theta [ 4.44066746 -2.47749359  2.52397015  6.90631132  3.4556707 ]\n",
      "error: 9.97989302649327e-07\n",
      "old_grad -0.0006682964747511335\n",
      "error_hist[-1:-50:-1] [9.97989302649327e-07, 1.000958952897691e-06, 1.0039417959253893e-06, 1.0069379015754248e-06, 1.0099473587866364e-06, 1.012970240606495e-06, 1.0160066304491788e-06, 1.019056605283935e-06, 1.0221202457008118e-06, 1.0251976365442672e-06, 1.0282888573765261e-06, 1.0313939889311854e-06, 1.0345131185047346e-06, 1.037646328243269e-06, 1.0407937019647241e-06, 1.0439553230177923e-06, 1.0471312822191506e-06, 1.0503216606012021e-06, 1.0535265482836988e-06, 1.0567460309034334e-06, 1.0599802017742174e-06, 1.0632291440235662e-06, 1.0664929462086796e-06, 1.0697717038677182e-06, 1.0730655084665794e-06, 1.076374445987266e-06, 1.0796986136141912e-06, 1.083038097887505e-06, 1.0863930082188195e-06, 1.089763418711618e-06, 1.09314943840845e-06, 1.096551158512836e-06, 1.0999686770730814e-06, 1.1034020931778923e-06, 1.1068514992537692e-06, 1.1103169962789657e-06, 1.1137986924486185e-06, 1.1172966758363732e-06, 1.1208110512299363e-06, 1.124341932834394e-06, 1.1278894014696457e-06, 1.1314535821472377e-06, 1.1350345668855767e-06, 1.1386324619147917e-06, 1.142247378631018e-06, 1.1458794174478565e-06, 1.1495286927091716e-06, 1.1531953073100863e-06, 1.1568793756317614e-06]\n",
      "Theta [ 3.70724603 -2.54290801  4.10823926  8.5216006   3.80893195]\n"
     ]
    }
   ],
   "source": [
    "Theta = get_grad_descent(X, Y)\n",
    "Theta2 = get_grad_descent_nesterov(X, Y)\n",
    "Theta3 = get_rmsprop(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta = [0 ,0, 0, 0, 0]\n",
    "Y_pred1 = get_predictions(X, Y, Theta)\n",
    "Y_pred2 = get_predictions(X, Y, Theta2)\n",
    "Y_pred3 = get_predictions(X, Y, Theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False False False\n",
      "1 False False False\n",
      "2 False False False\n",
      "3 False False False\n",
      "4 False False False\n",
      "5 False False False\n",
      "6 False False False\n",
      "7 False False False\n",
      "8 False False False\n",
      "9 False False False\n",
      "10 False False False\n",
      "11 False False False\n",
      "12 False False False\n",
      "13 False False False\n",
      "14 False False False\n",
      "15 False False False\n",
      "16 False False False\n",
      "17 False False False\n",
      "18 False False False\n",
      "19 False False False\n",
      "20 False False False\n",
      "21 False False False\n",
      "22 False False False\n",
      "23 False False False\n",
      "24 False False False\n",
      "25 False False False\n",
      "26 False False False\n",
      "27 False False False\n",
      "28 False False False\n",
      "29 False False False\n",
      "30 False False False\n",
      "31 False False False\n",
      "32 False False False\n",
      "33 False False False\n",
      "34 False False False\n",
      "35 False False False\n",
      "36 False False False\n",
      "37 False False False\n",
      "38 False False False\n",
      "39 False False False\n",
      "40 False False False\n",
      "41 False False False\n",
      "42 False False False\n",
      "43 False False False\n",
      "44 False False False\n",
      "45 False False False\n",
      "46 False False False\n",
      "47 False False False\n",
      "48 False False False\n",
      "49 False False False\n",
      "50 True True True\n",
      "51 True True True\n",
      "52 True True True\n",
      "53 True True True\n",
      "54 True True True\n",
      "55 True True True\n",
      "56 True True True\n",
      "57 True True True\n",
      "58 True True True\n",
      "59 True True True\n",
      "60 True True True\n",
      "61 True True True\n",
      "62 True True True\n",
      "63 True True True\n",
      "64 True True True\n",
      "65 True True True\n",
      "66 True True True\n",
      "67 True True True\n",
      "68 True True True\n",
      "69 True True True\n",
      "70 True True True\n",
      "71 True True True\n",
      "72 True True True\n",
      "73 True True True\n",
      "74 True True True\n",
      "75 True True True\n",
      "76 True True True\n",
      "77 True True True\n",
      "78 True True True\n",
      "79 True True True\n",
      "80 True True True\n",
      "81 True True True\n",
      "82 True True True\n",
      "83 True True True\n",
      "84 True True True\n",
      "85 True True True\n",
      "86 True True True\n",
      "87 True True True\n",
      "88 True True True\n",
      "89 True True True\n",
      "90 True True True\n",
      "91 True True True\n",
      "92 True True True\n",
      "93 True True True\n",
      "94 True True True\n",
      "95 True True True\n",
      "96 True True True\n",
      "97 True True True\n",
      "98 True True True\n",
      "99 True True True\n"
     ]
    }
   ],
   "source": [
    "# Проверка бестолковая, но как ещё не знаю\n",
    "for i in range(Y.shape[0]):\n",
    "    v1 = Y_pred1.iloc[i,0]\n",
    "    v2 = Y_pred2.iloc[i,0]\n",
    "    v3 = Y_pred3.iloc[i,0]\n",
    "    print(i, v1, v2, v3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.3595389  -3.54668855  5.03202702  5.17023197]\n",
      "0.7126655970299693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# No regularization\n",
    "lg = LogisticRegression(C=1e42)\n",
    "lg.fit(X, Y)\n",
    "print(lg.coef_[0])\n",
    "print(lg.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)\n",
      "0          -0.581066          0.841837\n",
      "1          -0.894309         -0.207835\n",
      "2          -1.207552          0.212034\n",
      "3          -1.364174          0.002099\n",
      "4          -0.737687          1.051772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "X.drop(['petal length (cm)','petal width (cm)'],axis=1,inplace=True)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "Name: target, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y[Y.columns[0]] == 0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ypos = (Y == 0).reshape(Y.shape[0],1)\n",
    "# Yneg = (Y == 1).reshape(Y.shape[0],1)\n",
    "Xpos = X[Y[Y.columns[0]] == 1]\n",
    "Xneg = X[Y[Y.columns[0]] == 0]\n",
    "Xpos = Xpos.dropna()\n",
    "Xneg = Xneg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length (cm)  sepal width (cm)\n",
      "50           2.394743          0.212034\n",
      "51           1.455014          0.212034\n",
      "52           2.238122          0.002099\n",
      "53           0.045420         -1.677376\n",
      "54           1.611636         -0.627704\n",
      "   sepal length (cm)  sepal width (cm)\n",
      "0          -0.581066          0.841837\n",
      "1          -0.894309         -0.207835\n",
      "2          -1.207552          0.212034\n",
      "3          -1.364174          0.002099\n",
      "4          -0.737687          1.051772\n"
     ]
    }
   ],
   "source": [
    "#print(Y == 0)\n",
    "print(Xpos.head())\n",
    "print(Xneg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6501058f98>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Xpos.iloc[:,0],Xpos.iloc[:,1],c=\"r\",marker=\"+\")\n",
    "plt.scatter(Xneg.iloc[:,0],Xneg.iloc[:,1],marker=\"o\",s=10)\n",
    "plt.xlabel(\"Exam 1 score\")\n",
    "plt.ylabel(\"Exam 2 score\")\n",
    "plt.legend([\"Admitted\",\"Not admitted\"],loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
